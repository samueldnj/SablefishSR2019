densPairs <- lapply (  FUN = dmvnorm, X = pairs, mean = c(v1m,v2m),
sigma=v1v2cov)
densPairs <- as.numeric(densPairs)
densPairs <- signif(densPairs/sum(densPairs),3)
names(densPairs) <- names(pairs)
postPairsDF <- data.frame(  OM = names(pairs),
Steepness= signif(pairsMat[,1],3),
B2018 = signif(pairsMat[,2],3),
density = densPairs )
rownames(postPairsDF) <- NULL
# Take mcmcDF, and turn into a table of posterior
# median estimates for
# B0, R0, M_f, M_m, h, B2019, Bmsy, Fmsy, MSY, B/Bmsy, B/B0
# calculate probability of being above LRP in 2018
# and 2016
mcmcProbLRP2018 <- mcmcDF %>%
mutate(OM = "2018 Fit") %>%
dplyr::select( OM,
B2018 = spawnB54,
B2016 = spawnB52,
Bmsy ) %>%
mutate( B2018gtLRP = ifelse( B2018 >= .4*Bmsy, 1, 0 ),
B2016gtLRP = ifelse( B2016 >= .4*Bmsy, 1, 0 ) ) %>%
group_by( OM ) %>%
summarise( ProbB2016GtLRP = as.character(round(mean(B2016gtLRP),2)),
ProbB2018GtLRP = as.character(round(mean(B2018gtLRP),2)) ) %>%
dplyr::select(  ProbB2016GtLRP,
ProbB2018GtLRP )
mcmcPostMean <- mcmcDF %>%
mutate(OM = "2018 Fit") %>%
dplyr::select(  OM,
B0 = "SSB0",
M_m,
M_f,
h,
B2016 = spawnB52,
B2018 = spawnB54,
Bmsy, Umsy, legUmsy, MSY ) %>%
mutate( D2016     = B2016/B0,
Dmsy2016  = B2016/Bmsy,
Dlrp2016  = B2016/(.4*Bmsy),
D2018     = B2018/B0,
Dmsy2018  = B2018/Bmsy,
Dlrp2018  = B2018/(.4*Bmsy) ) %>%
group_by(OM) %>%
summarise_if( is.numeric, summPostMeanSD, se = TRUE ) %>%
cbind( mcmcProbLRP2018 )
# read in mcmc output
mcmc2016    <- as.mcmc(read.table ("./data/mcoutMSY_2016.dat", header = TRUE) )
mcmcProbLRP2016 <- as.data.frame(mcmc2016) %>%
mutate(OM = "2016 Fit") %>%
dplyr::select( OM,
B2016 = spawnB52,
Bmsy ) %>%
mutate( B2016gtLRP = ifelse( B2016 >= .4*Bmsy, 1, 0 ) ) %>%
group_by( OM ) %>%
summarise( ProbB2016GtLRP = as.character(round(mean(B2016gtLRP),2)) ) %>%
mutate( ProbB2018GtLRP = NA ) %>%
dplyr::select(  ProbB2016GtLRP,
ProbB2018GtLRP)
mcmc2016    <- as.data.frame(mcmc2016) %>%
dplyr::select(  B0 = "SSB0",
M_m,
M_f,
h,
B2016 = spawnB52,
Bmsy, Umsy, legUmsy, MSY ) %>%
mutate( Dmsy2016 = B2016/Bmsy,
Dlrp2016 = B2016/(.4*Bmsy),
D2016 = B2016/B0 ) %>%
summarise_if( is.numeric, summPostMeanSD, se = TRUE ) %>%
mutate( B2018 = NA,
Dmsy2018 = NA,
Dlrp2018 = NA,
D2018 = NA,
OM    = "2016 Fit" ) %>%
dplyr::select(  OM,
B0,
M_m,
M_f,
h,
B2016,
B2018,
Bmsy, Umsy, legUmsy, MSY,
D2016,
Dmsy2016,
Dlrp2016,
D2018,
Dmsy2018,
Dlrp2018 ) %>%
cbind( mcmcProbLRP2016 )
# Start with var1var2mat, use covariance
# matrix to calculate distance from each
# centre
sampDist <- .6
subDists <- lapply( X = pairs, FUN = .mahalanobisDist,
post = mcmcDF,
pars = c("h","spawnB54"),
qProb = c("mean","mean"),
mDist = sampDist )
# Try a sampling system for h and SSB using
# Mahalnobis distance.
.mahalanobisDist <- function( centres = NULL,
post = mcmc,
pars = c("h","spawnB54"),
qProb = c("mean","mean"),
mDist = .3,
seed = NULL )
{
if( !is.null(seed) )
set.seed(seed)
# Reduce to the joint marginal we're interested in
subDist <- post[, pars ]
covMtx <- cov(subDist)
# Calc centre points for Mahalanobis calc if
# not explicitly  supplied
if(is.null(centres))
centres <- getCentre( subDist, pars, qProb )
# Now we loop over the distribution
# and calculate the dissimilarity bn
# the centre and each post point
subDist <-  subDist %>%
mutate( rIdx = 1:nrow(subDist),
mhnDist = NA )
for( rIdx in 1:nrow(subDist) )
{
postPoint <- as.matrix(subDist[rIdx,pars],nrow = 1)
diff      <- postPoint - as.numeric(centres)
subDist[rIdx,"mhnDist"] <-  mahalanobis(  x = postPoint,
center = centres,
cov = covMtx )
}
# Now reduce to points within mDist and randomly
# sample them
subDist <- subDist %>% filter( mhnDist < mDist )
# return
subDist
} # END .mahalanobisSample()
source(here::here("mseRtools.r"))
recDevYrs <- 10:52
recDevPad <- rep(0,recDevYrs[1]-1)
# read in mcmc output
mcmc    <- as.mcmc(read.table ("./data/mcoutMSY.dat", header = TRUE) )
mcmcDF  <- as.data.frame(mcmc)
# What two variables will we use, and what percentiles?
var1 <- "h"
var2 <- "spawnB54"
form <- paste(var2,"~",var1,sep = "")
var2Mat <- as.matrix(mcmc[,c(var1,var2)])
v1v2    <- lm ( as.formula(form), data = mcmcDF)
mean2d <- apply(X = var2Mat, FUN = mean, MARGIN = 2)
v1v2cov <- cov(var2Mat)
probs   <- c(0.1,0.9)
var1quants  <- quantile (mcmc[,var1], probs = probs)
v1m         <- mean (mcmc[,var1])
v2m         <- coef(v1v2)[1] + v1m*coef(v1v2)[2]
var2quants  <-  quantile(mcmc[,var2], probs=probs)
var2meanline  <-  coef(v1v2)[1] + var1quants*coef(v1v2)[2]
pairs <- list (   loB=c(v1m,var2quants[1]),
mhmB=c(v1m,v2m),
hiB=c(v1m,var2quants[2]),
loh=c(var1quants[1],var2meanline[1]),
hih=c(var1quants[2],var2meanline[2]))
pairsMat <- matrix(unlist(pairs),ncol = 2, byrow = TRUE)
densPairs <- lapply (  FUN = dmvnorm, X = pairs, mean = c(v1m,v2m),
sigma=v1v2cov)
densPairs <- as.numeric(densPairs)
densPairs <- signif(densPairs/sum(densPairs),3)
names(densPairs) <- names(pairs)
postPairsDF <- data.frame(  OM = names(pairs),
Steepness= signif(pairsMat[,1],3),
B2018 = signif(pairsMat[,2],3),
density = densPairs )
rownames(postPairsDF) <- NULL
# Take mcmcDF, and turn into a table of posterior
# median estimates for
# B0, R0, M_f, M_m, h, B2019, Bmsy, Fmsy, MSY, B/Bmsy, B/B0
# calculate probability of being above LRP in 2018
# and 2016
mcmcProbLRP2018 <- mcmcDF %>%
mutate(OM = "2018 Fit") %>%
dplyr::select( OM,
B2018 = spawnB54,
B2016 = spawnB52,
Bmsy ) %>%
mutate( B2018gtLRP = ifelse( B2018 >= .4*Bmsy, 1, 0 ),
B2016gtLRP = ifelse( B2016 >= .4*Bmsy, 1, 0 ) ) %>%
group_by( OM ) %>%
summarise( ProbB2016GtLRP = as.character(round(mean(B2016gtLRP),2)),
ProbB2018GtLRP = as.character(round(mean(B2018gtLRP),2)) ) %>%
dplyr::select(  ProbB2016GtLRP,
ProbB2018GtLRP )
mcmcPostMean <- mcmcDF %>%
mutate(OM = "2018 Fit") %>%
dplyr::select(  OM,
B0 = "SSB0",
M_m,
M_f,
h,
B2016 = spawnB52,
B2018 = spawnB54,
Bmsy, Umsy, legUmsy, MSY ) %>%
mutate( D2016     = B2016/B0,
Dmsy2016  = B2016/Bmsy,
Dlrp2016  = B2016/(.4*Bmsy),
D2018     = B2018/B0,
Dmsy2018  = B2018/Bmsy,
Dlrp2018  = B2018/(.4*Bmsy) ) %>%
group_by(OM) %>%
summarise_if( is.numeric, summPostMeanSD, se = TRUE ) %>%
cbind( mcmcProbLRP2018 )
# read in mcmc output
mcmc2016    <- as.mcmc(read.table ("./data/mcoutMSY_2016.dat", header = TRUE) )
mcmcProbLRP2016 <- as.data.frame(mcmc2016) %>%
mutate(OM = "2016 Fit") %>%
dplyr::select( OM,
B2016 = spawnB52,
Bmsy ) %>%
mutate( B2016gtLRP = ifelse( B2016 >= .4*Bmsy, 1, 0 ) ) %>%
group_by( OM ) %>%
summarise( ProbB2016GtLRP = as.character(round(mean(B2016gtLRP),2)) ) %>%
mutate( ProbB2018GtLRP = NA ) %>%
dplyr::select(  ProbB2016GtLRP,
ProbB2018GtLRP)
mcmc2016    <- as.data.frame(mcmc2016) %>%
dplyr::select(  B0 = "SSB0",
M_m,
M_f,
h,
B2016 = spawnB52,
Bmsy, Umsy, legUmsy, MSY ) %>%
mutate( Dmsy2016 = B2016/Bmsy,
Dlrp2016 = B2016/(.4*Bmsy),
D2016 = B2016/B0 ) %>%
summarise_if( is.numeric, summPostMeanSD, se = TRUE ) %>%
mutate( B2018 = NA,
Dmsy2018 = NA,
Dlrp2018 = NA,
D2018 = NA,
OM    = "2016 Fit" ) %>%
dplyr::select(  OM,
B0,
M_m,
M_f,
h,
B2016,
B2018,
Bmsy, Umsy, legUmsy, MSY,
D2016,
Dmsy2016,
Dlrp2016,
D2018,
Dmsy2018,
Dlrp2018 ) %>%
cbind( mcmcProbLRP2016 )
# Start with var1var2mat, use covariance
# matrix to calculate distance from each
# centre
sampDist <- .6
subDists <- lapply( X = pairs, FUN = .mahalanobisDist,
post = mcmcDF,
pars = c("h","spawnB54"),
qProb = c("mean","mean"),
mDist = sampDist )
subPosts <- subDists
for( i in 1:length(subPosts) )
{
subPosts[[i]] <- left_join( subPosts[[i]], mcmcDF, by = c("h","spawnB54") )
subPosts[[i]]$OM <- names(pairs)[i]
}
subPostOMs <- do.call(rbind,subPosts) %>%
dplyr::select(  OM,
B0 = "SSB0",
M_m,
M_f,
h,
B2016 = spawnB52,
B2018 = spawnB54,
Bmsy, Umsy, legUmsy, MSY ) %>%
mutate( D2016     = B2016/B0,
Dmsy2016  = B2016/Bmsy,
Dlrp2016  = B2016/(.4 * Bmsy),
D2018     = B2018/B0,
Dmsy2018  = B2018/Bmsy,
Dlrp2018  = B2018/(.4 * Bmsy) ) %>%
group_by(OM) %>%
summarise_if(is.numeric, summPostMeanSD) %>%
mutate( ProbB2016GtLRP = NA,
ProbB2018GtLRP = NA )
write.csv(mcmcPostMean, file = "mcmcPostMean.csv")
write.csv(subPostOMs, file = "subPostOMs_stats.csv")
#posteriorOMstats <- rbind(mcmc2016,mcmcPostMean,subPostOMs) # drop posterior strata so that table can be regular (instead of landscape) format
posteriorOMstats <- rbind(mcmc2016,mcmcPostMean)
OMnames <- posteriorOMstats$OM
rownames(posteriorOMstats) <- OMnames
posteriorOMstats$OM <- NULL
fancyRowNames <- c( "$B_0$",
"$M_m$",
"$M_f$",
"$h$",
"$B_{2016}$",
"$B_{2018}$",
"$B_{MSY}$",
"$U_{MSY}$",
"Legal $U_{MSY}$",
"$MSY$",
"$B_{2016}/B_0$",
"$B_{2016}/B_{MSY}$",
"$B_{2016}/(.4B_{MSY})$",
"$B_{2018}/B_0$",
"$B_{2018}/B_{MSY}$",
"$B_{2018}/(.4B_{MSY})$",
"$P(B_{2016} \\geq .4B_{MSY})$",
"$P(B_{2018} \\geq .4B_{MSY})$")
posteriorOMstats <- t(posteriorOMstats)
rownames(posteriorOMstats) <- fancyRowNames
posteriorOMstats
posteriorOMstats[1,1]
posteriorOMstats[1,6]
posteriorOMstats[6,1]
posteriorOMstats[6,1] <- "-"
posteriorOMstats[14:16,1] <- c("-","-","-")
posteriorOMstats
posteriorOMstats[18,1] <- "-"
source(here::here("mseRtools.r"))
recDevYrs <- 10:52
recDevPad <- rep(0,recDevYrs[1]-1)
# read in mcmc output
mcmc    <- as.mcmc(read.table ("./data/mcoutMSY.dat", header = TRUE) )
mcmcDF  <- as.data.frame(mcmc)
# What two variables will we use, and what percentiles?
var1 <- "h"
var2 <- "spawnB54"
form <- paste(var2,"~",var1,sep = "")
var2Mat <- as.matrix(mcmc[,c(var1,var2)])
v1v2    <- lm ( as.formula(form), data = mcmcDF)
mean2d <- apply(X = var2Mat, FUN = mean, MARGIN = 2)
v1v2cov <- cov(var2Mat)
probs   <- c(0.1,0.9)
var1quants  <- quantile (mcmc[,var1], probs = probs)
v1m         <- mean (mcmc[,var1])
v2m         <- coef(v1v2)[1] + v1m*coef(v1v2)[2]
var2quants  <-  quantile(mcmc[,var2], probs=probs)
var2meanline  <-  coef(v1v2)[1] + var1quants*coef(v1v2)[2]
pairs <- list (   loB=c(v1m,var2quants[1]),
mhmB=c(v1m,v2m),
hiB=c(v1m,var2quants[2]),
loh=c(var1quants[1],var2meanline[1]),
hih=c(var1quants[2],var2meanline[2]))
pairsMat <- matrix(unlist(pairs),ncol = 2, byrow = TRUE)
densPairs <- lapply (  FUN = dmvnorm, X = pairs, mean = c(v1m,v2m),
sigma=v1v2cov)
densPairs <- as.numeric(densPairs)
densPairs <- signif(densPairs/sum(densPairs),3)
names(densPairs) <- names(pairs)
postPairsDF <- data.frame(  OM = names(pairs),
Steepness= signif(pairsMat[,1],3),
B2018 = signif(pairsMat[,2],3),
density = densPairs )
rownames(postPairsDF) <- NULL
# Take mcmcDF, and turn into a table of posterior
# median estimates for
# B0, R0, M_f, M_m, h, B2019, Bmsy, Fmsy, MSY, B/Bmsy, B/B0
# calculate probability of being above LRP in 2018
# and 2016
mcmcProbLRP2018 <- mcmcDF %>%
mutate(OM = "2018 Fit") %>%
dplyr::select( OM,
B2018 = spawnB54,
B2016 = spawnB52,
Bmsy ) %>%
mutate( B2018gtLRP = ifelse( B2018 >= .4*Bmsy, 1, 0 ),
B2016gtLRP = ifelse( B2016 >= .4*Bmsy, 1, 0 ) ) %>%
group_by( OM ) %>%
summarise( ProbB2016GtLRP = as.character(round(mean(B2016gtLRP),2)),
ProbB2018GtLRP = as.character(round(mean(B2018gtLRP),2)) ) %>%
dplyr::select(  ProbB2016GtLRP,
ProbB2018GtLRP )
mcmcPostMean <- mcmcDF %>%
mutate(OM = "2018 Fit") %>%
dplyr::select(  OM,
B0 = "SSB0",
M_m,
M_f,
h,
B2016 = spawnB52,
B2018 = spawnB54,
Bmsy, Umsy, legUmsy, MSY ) %>%
mutate( D2016     = B2016/B0,
Dmsy2016  = B2016/Bmsy,
Dlrp2016  = B2016/(.4*Bmsy),
D2018     = B2018/B0,
Dmsy2018  = B2018/Bmsy,
Dlrp2018  = B2018/(.4*Bmsy) ) %>%
group_by(OM) %>%
summarise_if( is.numeric, summPostMeanSD, se = TRUE ) %>%
cbind( mcmcProbLRP2018 )
# read in mcmc output
mcmc2016    <- as.mcmc(read.table ("./data/mcoutMSY_2016.dat", header = TRUE) )
mcmcProbLRP2016 <- as.data.frame(mcmc2016) %>%
mutate(OM = "2016 Fit") %>%
dplyr::select( OM,
B2016 = spawnB52,
Bmsy ) %>%
mutate( B2016gtLRP = ifelse( B2016 >= .4*Bmsy, 1, 0 ) ) %>%
group_by( OM ) %>%
summarise( ProbB2016GtLRP = as.character(round(mean(B2016gtLRP),2)) ) %>%
mutate( ProbB2018GtLRP = NA ) %>%
dplyr::select(  ProbB2016GtLRP,
ProbB2018GtLRP)
mcmc2016    <- as.data.frame(mcmc2016) %>%
dplyr::select(  B0 = "SSB0",
M_m,
M_f,
h,
B2016 = spawnB52,
Bmsy, Umsy, legUmsy, MSY ) %>%
mutate( Dmsy2016 = B2016/Bmsy,
Dlrp2016 = B2016/(.4*Bmsy),
D2016 = B2016/B0 ) %>%
summarise_if( is.numeric, summPostMeanSD, se = TRUE ) %>%
mutate( B2018 = NA,
Dmsy2018 = NA,
Dlrp2018 = NA,
D2018 = NA,
OM    = "2016 Fit" ) %>%
dplyr::select(  OM,
B0,
M_m,
M_f,
h,
B2016,
B2018,
Bmsy, Umsy, legUmsy, MSY,
D2016,
Dmsy2016,
Dlrp2016,
D2018,
Dmsy2018,
Dlrp2018 ) %>%
cbind( mcmcProbLRP2016 )
# Start with var1var2mat, use covariance
# matrix to calculate distance from each
# centre
sampDist <- .6
subDists <- lapply( X = pairs, FUN = .mahalanobisDist,
post = mcmcDF,
pars = c("h","spawnB54"),
qProb = c("mean","mean"),
mDist = sampDist )
subPosts <- subDists
for( i in 1:length(subPosts) )
{
subPosts[[i]] <- left_join( subPosts[[i]], mcmcDF, by = c("h","spawnB54") )
subPosts[[i]]$OM <- names(pairs)[i]
}
subPostOMs <- do.call(rbind,subPosts) %>%
dplyr::select(  OM,
B0 = "SSB0",
M_m,
M_f,
h,
B2016 = spawnB52,
B2018 = spawnB54,
Bmsy, Umsy, legUmsy, MSY ) %>%
mutate( D2016     = B2016/B0,
Dmsy2016  = B2016/Bmsy,
Dlrp2016  = B2016/(.4 * Bmsy),
D2018     = B2018/B0,
Dmsy2018  = B2018/Bmsy,
Dlrp2018  = B2018/(.4 * Bmsy) ) %>%
group_by(OM) %>%
summarise_if(is.numeric, summPostMeanSD) %>%
mutate( ProbB2016GtLRP = NA,
ProbB2018GtLRP = NA )
write.csv(mcmcPostMean, file = "mcmcPostMean.csv")
write.csv(subPostOMs, file = "subPostOMs_stats.csv")
#posteriorOMstats <- rbind(mcmc2016,mcmcPostMean,subPostOMs) # drop posterior strata so that table can be regular (instead of landscape) format
posteriorOMstats <- rbind(mcmc2016,mcmcPostMean)
OMnames <- posteriorOMstats$OM
rownames(posteriorOMstats) <- OMnames
posteriorOMstats$OM <- NULL
fancyRowNames <- c( "$B_0$",
"$M_m$",
"$M_f$",
"$h$",
"$B_{2016}$",
"$B_{2018}$",
"$B_{MSY}$",
"$U_{MSY}$",
"Legal $U_{MSY}$",
"$MSY$",
"$B_{2016}/B_0$",
"$B_{2016}/B_{MSY}$",
"$B_{2016}/(.4B_{MSY})$",
"$B_{2018}/B_0$",
"$B_{2018}/B_{MSY}$",
"$B_{2018}/(.4B_{MSY})$",
"$P(B_{2016} \\geq .4B_{MSY})$",
"$P(B_{2018} \\geq .4B_{MSY})$")
posteriorOMstats
posteriorOMstats[6,1] <- "-"
posteriorOMstats[14:16,1] <- c("-","-","-")
posteriorOMstats[18,1] <- "-"
View(posteriorOMstats)
posteriorOMstats <- t(posteriorOMstats)
View(posteriorOMstats)
?csas_table
?add_header_above
devtools::install_github("pbs-assess/csasdown")
c( "l","l",rep("c", ncol(SP_refTable) - 2 ))
c( "l","l",rep("c", 10))
